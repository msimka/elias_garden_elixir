# Japanese Test Data for ELIAS Content Conversion

This file contains sample Japanese content for testing the ELIAS system's Japanese language processing capabilities.

## Sample 1: Basic Japanese Scripts

### Hiragana (ã²ã‚‰ãŒãª)
```
ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œã€‚
ã“ã‚Œã¯ã²ã‚‰ãŒãªã®ãƒ†ã‚¹ãƒˆã§ã™ã€‚
ã‚ã„ã†ãˆãŠã€ã‹ããã‘ã“ã€ã•ã—ã™ã›ãã€‚
```

### Katakana (ã‚«ã‚¿ã‚«ãƒŠ)
```
ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ»ã‚µã‚¤ã‚¨ãƒ³ã‚¹
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ»ã‚·ã‚¹ãƒ†ãƒ 
ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ»ãƒ†ã‚¹ãƒˆ
ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸
```

### Kanji (æ¼¢å­—)
```
æ—¥æœ¬èªè‡ªç„¶è¨€èªå‡¦ç†
æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
äººå·¥çŸ¥èƒ½ç ”ç©¶é–‹ç™º
æ·±å±¤å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
```

## Sample 2: Technical Documentation

### AIç ”ç©¶è«–æ–‡
```
## æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹æ—¥æœ¬èªè‡ªç„¶è¨€èªå‡¦ç†ã®é€²æ­©

### æ¦‚è¦
æœ¬ç ”ç©¶ã§ã¯ã€Transformer ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åŸºç›¤ã¨ã—ãŸæ—¥æœ¬èªè‡ªç„¶è¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«ã¤ã„ã¦å ±å‘Šã™ã‚‹ã€‚ç‰¹ã«ã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã€å˜èªãƒ¬ãƒ™ãƒ«ã€æ–‡ãƒ¬ãƒ™ãƒ«ã§ã®è¡¨ç¾å­¦ç¿’æ‰‹æ³•ã‚’çµ±åˆçš„ã«æ‰±ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚

### æŠ€è¡“çš„è²¢çŒ®
1. **å¤šå±¤è¡¨ç¾å­¦ç¿’**: ã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã®ç‰¹æ€§ã‚’æ´»ã‹ã—ãŸéšå±¤çš„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
2. **æ–‡è„ˆç†è§£ãƒ¢ãƒ‡ãƒ«**: åŠ©è©ãƒ»èªé †ã®ç‰¹æ€§ã‚’è€ƒæ…®ã—ãŸåŒæ–¹å‘æ³¨æ„æ©Ÿæ§‹
3. **åŠ¹ç‡çš„æ¨è«–**: æ—¥æœ¬èªç‰¹æœ‰ã®æ–‡å­—ä½“ç³»ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹æ³•

### å®Ÿé¨“çµæœ
| ã‚¿ã‚¹ã‚¯ | ç²¾åº¦ | F1ã‚¹ã‚³ã‚¢ | å‡¦ç†é€Ÿåº¦ |
|--------|------|----------|----------|
| æ–‡æ›¸åˆ†é¡ | 94.2% | 0.93 | 1,000æ–‡æ›¸/ç§’ |
| è³ªå•å¿œç­” | 87.1% | 0.924 | å¹³å‡150ms |
| è¦ç´„ç”Ÿæˆ | 89.7% | 0.891 | å¹³å‡300ms |

### ä»Šå¾Œã®èª²é¡Œ
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã®æœ€é©åŒ–
- ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œæ©Ÿèƒ½ã®å¼·åŒ–
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã¸ã®æ‹¡å¼µ
- æ–‡åŒ–çš„æ–‡è„ˆã®ç†è§£å‘ä¸Š
```

## Sample 3: Mixed Content Test

### æŠ€è¡“ä»•æ§˜æ›¸ï¼ˆæ—¥è‹±æ··åœ¨ï¼‰
```
# ELIAS Japanese Processing Specification

## ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶
- **å…¥åŠ›å½¢å¼**: PDF, DOCX, RTF, TXT
- **å‡ºåŠ›å½¢å¼**: Markdown, JSON, XML
- **å¯¾å¿œæ–‡å­—**: UTF-8 (JIS X 0213 å…¨æ–‡å­—)

### Performance Requirements
- å‡¦ç†é€Ÿåº¦: â‰¥ 10,000 characters/second
- Memory usage: â‰¤ 512MB per document
- Accuracy: â‰¥ 95% for text extraction

### API Endpoints
```elixir
# Document processing
ULM.ingest_document(path, :pdf, extract_knowledge: true)

# Text conversion
ULM.convert_text(:markdown, input_path, output_path, 
  language: "ja", 
  preserve_formatting: true)
```

## Testing Notes
- UTF-8 encoding preservation is critical
- Multi-byte character boundaries must be respected
- Japanese text segmentation differs from Latin scripts
- Cultural context affects AI model performance
```

## Sample 4: Complex Unicode Test

### Special Characters and Symbols
```
â˜…é‡è¦äº‹é …â˜…
â€»æ³¨æ„ç‚¹â€»
â—†å‚è€ƒè³‡æ–™â—†
â™ªéŸ³æ¥½é–¢é€£â™ª
ğŸŒæ—¥æœ¬ã®æ——ğŸŒ
ğŸ“šå­¦ç¿’æ•™æğŸ“š
ğŸ¤–AIãƒ»ãƒ­ãƒœãƒƒãƒˆğŸ¤–
âš¡é«˜é€Ÿå‡¦ç†âš¡
ğŸ”§ã‚·ã‚¹ãƒ†ãƒ èª¿æ•´ğŸ”§
```

### Full-width and Half-width Characters
```
å…¨è§’ï¼šï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—
åŠè§’ï¼šABCDEFG1234567
æ··åœ¨ï¼šABCã‚ã„ã†123ï½±ï½²ï½³ï¼ï¼Ÿã€‚
```

### Programming Code with Japanese Comments
```python
def æ—¥æœ¬èªå‡¦ç†é–¢æ•°(å…¥åŠ›ãƒ‡ãƒ¼ã‚¿):
    """
    æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹é–¢æ•°
    
    Args:
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ (str): å‡¦ç†å¯¾è±¡ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        dict: å‡¦ç†çµæœã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    """
    # å‰å‡¦ç†ï¼šæ–‡å­—æ­£è¦åŒ–
    æ­£è¦åŒ–æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ = å…¥åŠ›ãƒ‡ãƒ¼ã‚¿.strip().lower()
    
    # å½¢æ…‹ç´ è§£æ
    å½¢æ…‹ç´ ãƒªã‚¹ãƒˆ = tokenize(æ­£è¦åŒ–æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ)
    
    # çµæœè¿”å´
    return {
        'original': å…¥åŠ›ãƒ‡ãƒ¼ã‚¿,
        'normalized': æ­£è¦åŒ–æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ,
        'tokens': å½¢æ…‹ç´ ãƒªã‚¹ãƒˆ,
        'character_count': len(å…¥åŠ›ãƒ‡ãƒ¼ã‚¿),
        'processed_at': datetime.now()
    }
```

This test data can be used to validate:
1. UTF-8 encoding preservation
2. Japanese character recognition
3. Mixed script handling
4. Technical content processing
5. Special symbol preservation
6. Code comment extraction